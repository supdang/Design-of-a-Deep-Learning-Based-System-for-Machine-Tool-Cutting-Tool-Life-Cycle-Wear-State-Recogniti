#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é¢„å¤„ç†æ¨¡å—
å®ç°ä¿¡å·å»å™ªã€å½’ä¸€åŒ–ã€æ—¶é—´åºåˆ—åˆ‡åˆ†ç­‰é¢„å¤„ç†åŠŸèƒ½
"""

import numpy as np
from scipy import signal
from scipy.stats import zscore
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from typing import Tuple, Optional, List
import pywt
from ..utils.logger import get_module_logger
from ..config.config import PreprocessConfig, DataConfig

logger = get_module_logger(__name__)


class SignalPreprocessor:
    """ä¿¡å·é¢„å¤„ç†å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–é¢„å¤„ç†å™¨"""
        self.window_size = DataConfig.WINDOW_SIZE
        self.step_size = DataConfig.STEP_SIZE
        self.wavelet_name = PreprocessConfig.WAVELET_NAME
        self.decomposition_level = PreprocessConfig.DECOMPOSITION_LEVEL

        # åˆå§‹åŒ–scaler
        self.minmax_scaler = MinMaxScaler(feature_range=(0, 1))
        self.standard_scaler = StandardScaler()

    def wavelet_denoising(self, signal_data: np.ndarray) -> np.ndarray:
        """
        ä½¿ç”¨å°æ³¢å˜æ¢è¿›è¡Œä¿¡å·å»å™ª

        Args:
            signal_data: è¾“å…¥ä¿¡å·æ•°ç»„ (channels, samples)

        Returns:
            å»å™ªåçš„ä¿¡å·æ•°ç»„
        """
        try:
            denoised_data = np.zeros_like(signal_data)

            for channel in range(signal_data.shape[0]):
                # å°æ³¢åˆ†è§£
                coeffs = pywt.wavedec(
                    signal_data[channel],
                    self.wavelet_name,
                    level=self.decomposition_level
                )

                # è®¡ç®—é˜ˆå€¼
                sigma = np.median(np.abs(coeffs[-1])) / 0.6745
                threshold = sigma * np.sqrt(2 * np.log(len(signal_data[channel])))

                # è½¯é˜ˆå€¼å¤„ç†
                coeffs_thresh = list(coeffs)
                for i in range(1, len(coeffs)):
                    coeffs_thresh[i] = pywt.threshold(coeffs[i], threshold, mode='soft')

                # å°æ³¢é‡æ„
                denoised_data[channel] = pywt.waverec(coeffs_thresh, self.wavelet_name)

                # ç¡®ä¿é•¿åº¦ä¸€è‡´
                if len(denoised_data[channel]) != len(signal_data[channel]):
                    denoised_data[channel] = denoised_data[channel][:len(signal_data[channel])]

            logger.info(f"å°æ³¢å»å™ªå®Œæˆï¼ŒåŸå§‹å½¢çŠ¶: {signal_data.shape}, å¤„ç†åå½¢çŠ¶: {denoised_data.shape}")
            return denoised_data.astype(np.float32)

        except Exception as e:
            logger.error(f"å°æ³¢å»å™ªå¤±è´¥: {str(e)}")
            return signal_data

    def butterworth_filter(self, signal_data: np.ndarray,
                           lowcut: Optional[float] = None,
                           highcut: Optional[float] = None,
                           fs: int = DataConfig.SAMPLE_RATE) -> np.ndarray:
        """
        ä½¿ç”¨å·´ç‰¹æ²ƒæ–¯æ»¤æ³¢å™¨è¿›è¡Œä¿¡å·æ»¤æ³¢

        Args:
            signal_data: è¾“å…¥ä¿¡å·æ•°ç»„
            lowcut: ä½é¢‘æˆªæ­¢é¢‘ç‡ (Hz)
            highcut: é«˜é¢‘æˆªæ­¢é¢‘ç‡ (Hz)
            fs: é‡‡æ ·é¢‘ç‡ (Hz)

        Returns:
            æ»¤æ³¢åçš„ä¿¡å·æ•°ç»„
        """
        try:
            nyquist = 0.5 * fs

            if lowcut is not None and highcut is not None:
                # å¸¦é€šæ»¤æ³¢
                low = lowcut / nyquist
                high = highcut / nyquist
                b, a = signal.butter(4, [low, high], btype='band')
            elif lowcut is not None:
                # é«˜é€šæ»¤æ³¢
                low = lowcut / nyquist
                b, a = signal.butter(4, low, btype='high')
            elif highcut is not None:
                # ä½é€šæ»¤æ³¢
                high = highcut / nyquist
                b, a = signal.butter(4, high, btype='low')
            else:
                return signal_data

            filtered_data = np.zeros_like(signal_data)
            for channel in range(signal_data.shape[0]):
                filtered_data[channel] = signal.filtfilt(b, a, signal_data[channel])

            logger.info(f"å·´ç‰¹æ²ƒæ–¯æ»¤æ³¢å®Œæˆï¼Œæ»¤æ³¢å™¨ç±»å‹: {self._get_filter_type(lowcut, highcut)}")
            return filtered_data.astype(np.float32)

        except Exception as e:
            logger.error(f"å·´ç‰¹æ²ƒæ–¯æ»¤æ³¢å¤±è´¥: {str(e)}")
            return signal_data

    def _get_filter_type(self, lowcut: Optional[float], highcut: Optional[float]) -> str:
        """è·å–æ»¤æ³¢å™¨ç±»å‹"""
        if lowcut is not None and highcut is not None:
            return f"å¸¦é€šæ»¤æ³¢ ({lowcut}-{highcut} Hz)"
        elif lowcut is not None:
            return f"é«˜é€šæ»¤æ³¢ ({lowcut} Hz)"
        elif highcut is not None:
            return f"ä½é€šæ»¤æ³¢ ({highcut} Hz)"
        else:
            return "æ— æ»¤æ³¢"

    def normalize_signal(self, signal_data: np.ndarray,
                         method: str = 'minmax') -> np.ndarray:
        """
        ä¿¡å·å½’ä¸€åŒ–å¤„ç†

        Args:
            signal_data: è¾“å…¥ä¿¡å·æ•°ç»„
            method: å½’ä¸€åŒ–æ–¹æ³• ('minmax', 'standard', 'zscore')

        Returns:
            å½’ä¸€åŒ–åçš„ä¿¡å·æ•°ç»„
        """
        try:
            normalized_data = np.zeros_like(signal_data)

            for channel in range(signal_data.shape[0]):
                signal_channel = signal_data[channel].reshape(-1, 1)

                if method == 'minmax':
                    # Min-Maxå½’ä¸€åŒ–åˆ°[0,1]
                    normalized_data[channel] = self.minmax_scaler.fit_transform(signal_channel).flatten()
                elif method == 'standard':
                    # æ ‡å‡†åŒ–åˆ°å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1
                    normalized_data[channel] = self.standard_scaler.fit_transform(signal_channel).flatten()
                elif method == 'zscore':
                    # Z-scoreæ ‡å‡†åŒ–
                    normalized_data[channel] = zscore(signal_data[channel])
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„å½’ä¸€åŒ–æ–¹æ³•: {method}")

            logger.info(f"ä¿¡å·å½’ä¸€åŒ–å®Œæˆï¼Œæ–¹æ³•: {method}")
            return normalized_data.astype(np.float32)

        except Exception as e:
            logger.error(f"ä¿¡å·å½’ä¸€åŒ–å¤±è´¥: {str(e)}")
            return signal_data

    def create_sliding_windows(self, signal_data: np.ndarray,
                               labels: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        ä½¿ç”¨æ»‘åŠ¨çª—å£åˆ›å»ºæ—¶é—´åºåˆ—æ ·æœ¬

        Args:
            signal_data: è¾“å…¥ä¿¡å·æ•°ç»„ (channels, samples)
            labels: æ ‡ç­¾æ•°ç»„ (samples,)

        Returns:
            (windows, window_labels) å…ƒç»„
        """
        try:
            n_channels, n_samples = signal_data.shape

            # è®¡ç®—çª—å£æ•°é‡
            n_windows = (n_samples - self.window_size) // self.step_size + 1

            # åˆå§‹åŒ–çª—å£æ•°ç»„
            windows = np.zeros((n_windows, n_channels, self.window_size), dtype=np.float32)
            window_labels = np.zeros(n_windows, dtype=np.int32)

            # åˆ›å»ºæ»‘åŠ¨çª—å£
            for i in range(n_windows):
                start_idx = i * self.step_size
                end_idx = start_idx + self.window_size

                # æå–çª—å£æ•°æ®
                windows[i] = signal_data[:, start_idx:end_idx]

                # çª—å£æ ‡ç­¾é‡‡ç”¨çª—å£ä¸­é—´ä½ç½®çš„æ ‡ç­¾
                mid_idx = start_idx + self.window_size // 2
                if mid_idx < len(labels):
                    window_labels[i] = labels[mid_idx]
                else:
                    window_labels[i] = labels[-1]

            logger.info(f"åˆ›å»ºæ»‘åŠ¨çª—å£å®Œæˆï¼Œçª—å£æ•°é‡: {n_windows}, çª—å£å¤§å°: {self.window_size}")
            return windows, window_labels

        except Exception as e:
            logger.error(f"åˆ›å»ºæ»‘åŠ¨çª—å£å¤±è´¥: {str(e)}")
            return signal_data[np.newaxis, :, :], labels[np.newaxis]

    def extract_statistical_features(self, signal_data: np.ndarray) -> np.ndarray:
        """
        æå–ç»Ÿè®¡ç‰¹å¾

        Args:
            signal_data: è¾“å…¥ä¿¡å·æ•°ç»„ (channels, samples)

        Returns:
            ç‰¹å¾æ•°ç»„
        """
        try:
            n_channels, n_samples = signal_data.shape
            features = []

            for channel in range(n_channels):
                signal_channel = signal_data[channel]

                # æ—¶åŸŸç‰¹å¾
                mean = np.mean(signal_channel)
                std = np.std(signal_channel)
                rms = np.sqrt(np.mean(signal_channel ** 2))
                peak = np.max(np.abs(signal_channel))
                peak_to_peak = np.max(signal_channel) - np.min(signal_channel)
                skewness = self._calculate_skewness(signal_channel)
                kurtosis = self._calculate_kurtosis(signal_channel)

                # é¢‘åŸŸç‰¹å¾
                fft_spectrum = np.fft.fft(signal_channel)
                magnitude = np.abs(fft_spectrum)
                power = magnitude ** 2

                spectral_centroid = np.sum(np.arange(len(power)) * power) / np.sum(power)
                spectral_bandwidth = np.sqrt(
                    np.sum(((np.arange(len(power)) - spectral_centroid) ** 2) * power) / np.sum(power))

                channel_features = [
                    mean, std, rms, peak, peak_to_peak, skewness, kurtosis,
                    spectral_centroid, spectral_bandwidth
                ]

                features.extend(channel_features)

            return np.array(features, dtype=np.float32)

        except Exception as e:
            logger.error(f"æå–ç»Ÿè®¡ç‰¹å¾å¤±è´¥: {str(e)}")
            return np.array([])

    def _calculate_skewness(self, data: np.ndarray) -> float:
        """è®¡ç®—ååº¦"""
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0
        return np.mean(((data - mean) / std) ** 3)

    def _calculate_kurtosis(self, data: np.ndarray) -> float:
        """è®¡ç®—å³°åº¦"""
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0
        return np.mean(((data - mean) / std) ** 4) - 3

    def remove_outliers(self, signal_data: np.ndarray,
                        threshold: float = 3.0) -> np.ndarray:
        """
        å»é™¤å¼‚å¸¸å€¼

        Args:
            signal_data: è¾“å…¥ä¿¡å·æ•°ç»„
            threshold: å¼‚å¸¸å€¼é˜ˆå€¼ï¼ˆæ ‡å‡†å·®å€æ•°ï¼‰

        Returns:
            å»é™¤å¼‚å¸¸å€¼åçš„ä¿¡å·æ•°ç»„
        """
        try:
            cleaned_data = np.zeros_like(signal_data)

            for channel in range(signal_data.shape[0]):
                signal_channel = signal_data[channel]

                # è®¡ç®—Z-score
                z_scores = np.abs(zscore(signal_channel))

                # æ ‡è®°å¼‚å¸¸å€¼
                outlier_mask = z_scores > threshold

                # ä½¿ç”¨æ’å€¼æ›¿æ¢å¼‚å¸¸å€¼
                if np.any(outlier_mask):
                    x = np.arange(len(signal_channel))
                    good_indices = ~outlier_mask

                    if np.any(good_indices):
                        cleaned_data[channel] = np.interp(
                            x, x[good_indices], signal_channel[good_indices]
                        )
                    else:
                        cleaned_data[channel] = signal_channel
                else:
                    cleaned_data[channel] = signal_channel

            logger.info(f"å¼‚å¸¸å€¼å»é™¤å®Œæˆï¼Œé˜ˆå€¼: {threshold}")
            return cleaned_data.astype(np.float32)

        except Exception as e:
            logger.error(f"å¼‚å¸¸å€¼å»é™¤å¤±è´¥: {str(e)}")
            return signal_data

    def apply_data_augmentation(self, signal_data: np.ndarray,
                                noise_level: float = 0.01,
                                scale_range: tuple = (0.8, 1.2)) -> np.ndarray:
        """
        åº”ç”¨æ•°æ®å¢å¼º

        Args:
            signal_data: è¾“å…¥ä¿¡å·æ•°ç»„
            noise_level: å™ªå£°æ°´å¹³
            scale_range: ç¼©æ”¾èŒƒå›´

        Returns:
            å¢å¼ºåçš„ä¿¡å·æ•°ç»„
        """
        try:
            augmented_data = np.zeros_like(signal_data)

            for channel in range(signal_data.shape[0]):
                signal_channel = signal_data[channel]

                # æ·»åŠ é«˜æ–¯å™ªå£°
                noise = np.random.normal(0, noise_level * np.std(signal_channel), signal_channel.shape)
                augmented_signal = signal_channel + noise

                # å¹…åº¦ç¼©æ”¾
                scale_factor = np.random.uniform(scale_range[0], scale_range[1])
                augmented_signal = augmented_signal * scale_factor

                augmented_data[channel] = augmented_signal

            logger.info(f"æ•°æ®å¢å¼ºå®Œæˆï¼Œå™ªå£°æ°´å¹³: {noise_level}, ç¼©æ”¾èŒƒå›´: {scale_range}")
            return augmented_data.astype(np.float32)

        except Exception as e:
            logger.error(f"æ•°æ®å¢å¼ºå¤±è´¥: {str(e)}")
            return signal_data

    def preprocess_pipeline(self, signal_data: np.ndarray,
                            labels: Optional[np.ndarray] = None,
                            apply_denoising: bool = True,
                            apply_filtering: bool = True,
                            apply_normalization: bool = True,
                            apply_outlier_removal: bool = True,
                            create_windows: bool = True) -> Tuple[np.ndarray, Optional[np.ndarray]]:
        """
        å®Œæ•´çš„é¢„å¤„ç†æµæ°´çº¿

        Args:
            signal_data: è¾“å…¥ä¿¡å·æ•°ç»„
            labels: æ ‡ç­¾æ•°ç»„
            apply_denoising: æ˜¯å¦åº”ç”¨å»å™ª
            apply_filtering: æ˜¯å¦åº”ç”¨æ»¤æ³¢
            apply_normalization: æ˜¯å¦åº”ç”¨å½’ä¸€åŒ–
            apply_outlier_removal: æ˜¯å¦å»é™¤å¼‚å¸¸å€¼
            create_windows: æ˜¯å¦åˆ›å»ºæ»‘åŠ¨çª—å£

        Returns:
            (processed_data, processed_labels) å…ƒç»„
        """
        logger.info("å¼€å§‹é¢„å¤„ç†æµæ°´çº¿")
        processed_data = signal_data.copy()

        try:
            # 1. å¼‚å¸¸å€¼å»é™¤
            if apply_outlier_removal:
                processed_data = self.remove_outliers(processed_data)
                logger.info("å¼‚å¸¸å€¼å»é™¤å®Œæˆ")

            # 2. ä¿¡å·å»å™ª
            if apply_denoising:
                processed_data = self.wavelet_denoising(processed_data)
                logger.info("ä¿¡å·å»å™ªå®Œæˆ")

            # 3. ä¿¡å·æ»¤æ³¢
            if apply_filtering:
                processed_data = self.butterworth_filter(processed_data, highcut=10000)
                logger.info("ä¿¡å·æ»¤æ³¢å®Œæˆ")

            # 4. ä¿¡å·å½’ä¸€åŒ–
            if apply_normalization:
                processed_data = self.normalize_signal(processed_data, method='minmax')
                logger.info("ä¿¡å·å½’ä¸€åŒ–å®Œæˆ")

            # 5. åˆ›å»ºæ»‘åŠ¨çª—å£
            if create_windows and labels is not None:
                window_data, window_labels = self.create_sliding_windows(processed_data, labels)
                # ğŸ‘‰ğŸ‘‰ğŸ‘‰ å…³é”®ä¿®å¤ï¼šè½¬ç½®æ•°æ®å½¢çŠ¶ ğŸ‘ˆğŸ‘ˆğŸ‘ˆ
                # ä» (n_windows, n_channels, window_size) è½¬æ¢ä¸º (n_windows, window_size, n_channels)
                window_data = np.transpose(window_data, (0, 2, 1))
                logger.info(f"æ»‘åŠ¨çª—å£åˆ›å»ºå®Œæˆï¼Œè½¬ç½®åå½¢çŠ¶: {window_data.shape}")
                return window_data, window_labels

            logger.info("é¢„å¤„ç†æµæ°´çº¿å®Œæˆ")
            return processed_data, labels

        except Exception as e:
            logger.error(f"é¢„å¤„ç†æµæ°´çº¿å¤±è´¥: {str(e)}")
            return signal_data, labels